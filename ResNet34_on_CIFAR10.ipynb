{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Engineer-Ayesha-Shafique/Neural-Network-Using-PyTorch/blob/main/ResNet34_on_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT5JxSk6f2PB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ssqjRc8BfmCc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i7AtjnPgELJ"
      },
      "source": [
        "# Loading Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lTIESz9gLj3"
      },
      "source": [
        "1. Defining data_loader function - returns the training or test data depending on the arguments.\n",
        "2. Normalizing our data makes the training faster and easier to converge. We define the variable normalize with the mean and standard deviations of each of the channel (red, green, and blue) in the dataset.\n",
        "3. It is used in the transform variable where we resize the data, convert it to tensors and then normalize it.\n",
        "4. Data loaders allow us to iterate through the data in batches, and the data is loaded while iterating and not all at once in start into our RAM.\n",
        "5.  Depending on the test argument, we either load the train (if test=False) split or the test ( if test=True) split. In case of train, the split is randomly divided into train and validation set (0.9:0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1r9r03lgGxL",
        "outputId": "4bdf4b9d-cc8e-4ebd-ac85-f5685fbbbcfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12939115.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "def data_loader(data_dir,\n",
        "                batch_size,\n",
        "                random_seed=42,\n",
        "                valid_size=0.1,\n",
        "                shuffle=True,\n",
        "                test=False):\n",
        "  \n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.2010],\n",
        "    )\n",
        "\n",
        "\n",
        "    # define transforms\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize((224,224)),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "    ])\n",
        "\n",
        "    if test:\n",
        "        dataset = datasets.CIFAR10(\n",
        "          root=data_dir, train=False,\n",
        "          download=True, transform=transform,\n",
        "        )\n",
        "\n",
        "        data_loader = torch.utils.data.DataLoader(\n",
        "            dataset, batch_size=batch_size, shuffle=shuffle\n",
        "        )\n",
        "\n",
        "        return data_loader\n",
        "\n",
        "\n",
        "    # load the dataset\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=True,\n",
        "        download=True, transform=transform,\n",
        "    )\n",
        "\n",
        "    valid_dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=True,\n",
        "        download=True, transform=transform,\n",
        "    )\n",
        "\n",
        "    num_train = len(train_dataset)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.seed(42)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        " \n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "    return (train_loader, valid_loader)\n",
        "\n",
        "\n",
        "# CIFAR10 dataset \n",
        "train_loader, valid_loader = data_loader(data_dir='./data',\n",
        "                                         batch_size=64)\n",
        "\n",
        "test_loader = data_loader(data_dir='./data',\n",
        "                              batch_size=64,\n",
        "                              test=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm2MwXIlGF6E"
      },
      "source": [
        "# Residual Block\n",
        "The block contains a skip connection that is an optional parameter (downsample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C17CLIKJGYWD"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n",
        "                        nn.BatchNorm2d(out_channels),\n",
        "                        nn.ReLU())\n",
        "        self.conv2 = nn.Sequential(\n",
        "                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
        "                        nn.BatchNorm2d(out_channels))\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU()\n",
        "        self.out_channels = out_channels\n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MY0-QEMGhfJ"
      },
      "source": [
        "# ResNet\n",
        "\n",
        "There are three blocks in the architecture, containing 3, 3, 6, and 3 layers respectively. To make this block, we create a helper function _make_layer. The function adds the layers one by one along with the Residual Block. After the blocks, we add the average pooling and the final linear layer.\n",
        "\n",
        "\n",
        "\n",
        "*   nn.Module provides a boilerplate for creating custom models along with some necessary functionality that helps in training. It provides a convenient way to define, organize and parameterize layers of a neural network.\n",
        "*   Then there are two main functions inside every custom model. First is the initialization function, __init__, where we define the various layers we will be using, and second is the forward function, which defines the sequence in which the above layers will be executed on a given input\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MwpgHEnNUF4"
      },
      "source": [
        "# Layers\n",
        "\n",
        "(number of input channels = number of \n",
        "color channels in input\n",
        "number of output channels = number of filters)\n",
        "\n",
        "\n",
        "\n",
        "*   nn.Conv2d: These are the convolutional layers that accepts the number of input and output channels as arguments, along with kernel size for the filter. It also accepts any strides or padding if we want to apply those.\n",
        "\n",
        "* nn.BatchNorm2d: This applies batch normalization to the output from the convolutional layer\n",
        "* nn.ReLU: This is a type of  activation function applied to various outputs in the network\n",
        "* nn.MaxPool2d : This applies max pooling to the output with the kernel size given\n",
        "* nn.Dropout: This is used to apply dropout to the output with a given probability\n",
        "* nn.Linear: This is basically a fully connected layer\n",
        "* nn.Sequential: This is technically not a type of layer but it helps in combining different operations that are part of the same step\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WaP1ITCCGrjc"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes = 10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.inplanes = 64\n",
        "        self.conv1 = nn.Sequential(\n",
        "                        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ReLU())\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
        "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
        "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
        "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "        \n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes:\n",
        "            \n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer0(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzewtNtHGxgA"
      },
      "source": [
        "# Setting Hyperparameters\n",
        "The hyper-parameters include defining the number of epochs, batch size, learning rate, loss function along with the optimizer. As we are building the 34 layer variant of ResNet, we need to pass the appropriate number of layers as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q8l7-GblG6fo"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "num_epochs = 20\n",
        "batch_size = 16\n",
        "learning_rate = 0.01\n",
        "\n",
        "model = ResNet(ResidualBlock, [3, 4, 6, 3]).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9)  \n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTAYSFQxro4q"
      },
      "source": [
        "# State_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHHITKDxrtuJ",
        "outputId": "6a5fe7ec-58ac-4a9c-fbfc-fe2318875033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's state_dict:\n",
            "conv1.0.weight \t torch.Size([64, 3, 7, 7])\n",
            "conv1.0.bias \t torch.Size([64])\n",
            "conv1.1.weight \t torch.Size([64])\n",
            "conv1.1.bias \t torch.Size([64])\n",
            "conv1.1.running_mean \t torch.Size([64])\n",
            "conv1.1.running_var \t torch.Size([64])\n",
            "conv1.1.num_batches_tracked \t torch.Size([])\n",
            "layer0.0.conv1.0.weight \t torch.Size([64, 64, 3, 3])\n",
            "layer0.0.conv1.0.bias \t torch.Size([64])\n",
            "layer0.0.conv1.1.weight \t torch.Size([64])\n",
            "layer0.0.conv1.1.bias \t torch.Size([64])\n",
            "layer0.0.conv1.1.running_mean \t torch.Size([64])\n",
            "layer0.0.conv1.1.running_var \t torch.Size([64])\n",
            "layer0.0.conv1.1.num_batches_tracked \t torch.Size([])\n",
            "layer0.0.conv2.0.weight \t torch.Size([64, 64, 3, 3])\n",
            "layer0.0.conv2.0.bias \t torch.Size([64])\n",
            "layer0.0.conv2.1.weight \t torch.Size([64])\n",
            "layer0.0.conv2.1.bias \t torch.Size([64])\n",
            "layer0.0.conv2.1.running_mean \t torch.Size([64])\n",
            "layer0.0.conv2.1.running_var \t torch.Size([64])\n",
            "layer0.0.conv2.1.num_batches_tracked \t torch.Size([])\n",
            "layer0.1.conv1.0.weight \t torch.Size([64, 64, 3, 3])\n",
            "layer0.1.conv1.0.bias \t torch.Size([64])\n",
            "layer0.1.conv1.1.weight \t torch.Size([64])\n",
            "layer0.1.conv1.1.bias \t torch.Size([64])\n",
            "layer0.1.conv1.1.running_mean \t torch.Size([64])\n",
            "layer0.1.conv1.1.running_var \t torch.Size([64])\n",
            "layer0.1.conv1.1.num_batches_tracked \t torch.Size([])\n",
            "layer0.1.conv2.0.weight \t torch.Size([64, 64, 3, 3])\n",
            "layer0.1.conv2.0.bias \t torch.Size([64])\n",
            "layer0.1.conv2.1.weight \t torch.Size([64])\n",
            "layer0.1.conv2.1.bias \t torch.Size([64])\n",
            "layer0.1.conv2.1.running_mean \t torch.Size([64])\n",
            "layer0.1.conv2.1.running_var \t torch.Size([64])\n",
            "layer0.1.conv2.1.num_batches_tracked \t torch.Size([])\n",
            "layer0.2.conv1.0.weight \t torch.Size([64, 64, 3, 3])\n",
            "layer0.2.conv1.0.bias \t torch.Size([64])\n",
            "layer0.2.conv1.1.weight \t torch.Size([64])\n",
            "layer0.2.conv1.1.bias \t torch.Size([64])\n",
            "layer0.2.conv1.1.running_mean \t torch.Size([64])\n",
            "layer0.2.conv1.1.running_var \t torch.Size([64])\n",
            "layer0.2.conv1.1.num_batches_tracked \t torch.Size([])\n",
            "layer0.2.conv2.0.weight \t torch.Size([64, 64, 3, 3])\n",
            "layer0.2.conv2.0.bias \t torch.Size([64])\n",
            "layer0.2.conv2.1.weight \t torch.Size([64])\n",
            "layer0.2.conv2.1.bias \t torch.Size([64])\n",
            "layer0.2.conv2.1.running_mean \t torch.Size([64])\n",
            "layer0.2.conv2.1.running_var \t torch.Size([64])\n",
            "layer0.2.conv2.1.num_batches_tracked \t torch.Size([])\n",
            "layer1.0.conv1.0.weight \t torch.Size([128, 64, 3, 3])\n",
            "layer1.0.conv1.0.bias \t torch.Size([128])\n",
            "layer1.0.conv1.1.weight \t torch.Size([128])\n",
            "layer1.0.conv1.1.bias \t torch.Size([128])\n",
            "layer1.0.conv1.1.running_mean \t torch.Size([128])\n",
            "layer1.0.conv1.1.running_var \t torch.Size([128])\n",
            "layer1.0.conv1.1.num_batches_tracked \t torch.Size([])\n",
            "layer1.0.conv2.0.weight \t torch.Size([128, 128, 3, 3])\n",
            "layer1.0.conv2.0.bias \t torch.Size([128])\n",
            "layer1.0.conv2.1.weight \t torch.Size([128])\n",
            "layer1.0.conv2.1.bias \t torch.Size([128])\n",
            "layer1.0.conv2.1.running_mean \t torch.Size([128])\n",
            "layer1.0.conv2.1.running_var \t torch.Size([128])\n",
            "layer1.0.conv2.1.num_batches_tracked \t torch.Size([])\n",
            "layer1.0.downsample.0.weight \t torch.Size([128, 64, 1, 1])\n",
            "layer1.0.downsample.0.bias \t torch.Size([128])\n",
            "layer1.0.downsample.1.weight \t torch.Size([128])\n",
            "layer1.0.downsample.1.bias \t torch.Size([128])\n",
            "layer1.0.downsample.1.running_mean \t torch.Size([128])\n",
            "layer1.0.downsample.1.running_var \t torch.Size([128])\n",
            "layer1.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
            "layer1.1.conv1.0.weight \t torch.Size([128, 128, 3, 3])\n",
            "layer1.1.conv1.0.bias \t torch.Size([128])\n",
            "layer1.1.conv1.1.weight \t torch.Size([128])\n",
            "layer1.1.conv1.1.bias \t torch.Size([128])\n",
            "layer1.1.conv1.1.running_mean \t torch.Size([128])\n",
            "layer1.1.conv1.1.running_var \t torch.Size([128])\n",
            "layer1.1.conv1.1.num_batches_tracked \t torch.Size([])\n",
            "layer1.1.conv2.0.weight \t torch.Size([128, 128, 3, 3])\n",
            "layer1.1.conv2.0.bias \t torch.Size([128])\n",
            "layer1.1.conv2.1.weight \t torch.Size([128])\n",
            "layer1.1.conv2.1.bias \t torch.Size([128])\n",
            "layer1.1.conv2.1.running_mean \t torch.Size([128])\n",
            "layer1.1.conv2.1.running_var \t torch.Size([128])\n",
            "layer1.1.conv2.1.num_batches_tracked \t torch.Size([])\n",
            "layer1.2.conv1.0.weight \t torch.Size([128, 128, 3, 3])\n",
            "layer1.2.conv1.0.bias \t torch.Size([128])\n",
            "layer1.2.conv1.1.weight \t torch.Size([128])\n",
            "layer1.2.conv1.1.bias \t torch.Size([128])\n",
            "layer1.2.conv1.1.running_mean \t torch.Size([128])\n",
            "layer1.2.conv1.1.running_var \t torch.Size([128])\n",
            "layer1.2.conv1.1.num_batches_tracked \t torch.Size([])\n",
            "layer1.2.conv2.0.weight \t torch.Size([128, 128, 3, 3])\n",
            "layer1.2.conv2.0.bias \t torch.Size([128])\n",
            "layer1.2.conv2.1.weight \t torch.Size([128])\n",
            "layer1.2.conv2.1.bias \t torch.Size([128])\n",
            "layer1.2.conv2.1.running_mean \t torch.Size([128])\n",
            "layer1.2.conv2.1.running_var \t torch.Size([128])\n",
            "layer1.2.conv2.1.num_batches_tracked \t torch.Size([])\n",
            "layer1.3.conv1.0.weight \t torch.Size([128, 128, 3, 3])\n",
            "layer1.3.conv1.0.bias \t torch.Size([128])\n",
            "layer1.3.conv1.1.weight \t torch.Size([128])\n",
            "layer1.3.conv1.1.bias \t torch.Size([128])\n",
            "layer1.3.conv1.1.running_mean \t torch.Size([128])\n",
            "layer1.3.conv1.1.running_var \t torch.Size([128])\n",
            "layer1.3.conv1.1.num_batches_tracked \t torch.Size([])\n",
            "layer1.3.conv2.0.weight \t torch.Size([128, 128, 3, 3])\n",
            "layer1.3.conv2.0.bias \t torch.Size([128])\n",
            "layer1.3.conv2.1.weight \t torch.Size([128])\n",
            "layer1.3.conv2.1.bias \t torch.Size([128])\n",
            "layer1.3.conv2.1.running_mean \t torch.Size([128])\n",
            "layer1.3.conv2.1.running_var \t torch.Size([128])\n",
            "layer1.3.conv2.1.num_batches_tracked \t torch.Size([])\n",
            "layer2.0.conv1.0.weight \t torch.Size([256, 128, 3, 3])\n",
            "layer2.0.conv1.0.bias \t torch.Size([256])\n",
            "layer2.0.conv1.1.weight \t torch.Size([256])\n",
            "layer2.0.conv1.1.bias \t torch.Size([256])\n",
            "layer2.0.conv1.1.running_mean \t torch.Size([256])\n",
            "layer2.0.conv1.1.running_var \t torch.Size([256])\n",
            "layer2.0.conv1.1.num_batches_tracked \t torch.Size([])\n",
            "layer2.0.conv2.0.weight \t torch.Size([256, 256, 3, 3])\n",
            "layer2.0.conv2.0.bias \t torch.Size([256])\n",
            "layer2.0.conv2.1.weight \t torch.Size([256])\n",
            "layer2.0.conv2.1.bias \t torch.Size([256])\n",
            "layer2.0.conv2.1.running_mean \t torch.Size([256])\n",
            "layer2.0.conv2.1.running_var \t torch.Size([256])\n",
            "layer2.0.conv2.1.num_batches_tracked \t torch.Size([])\n",
            "layer2.0.downsample.0.weight \t torch.Size([256, 128, 1, 1])\n",
            "layer2.0.downsample.0.bias \t torch.Size([256])\n",
            "layer2.0.downsample.1.weight \t torch.Size([256])\n",
            "layer2.0.downsample.1.bias \t torch.Size([256])\n",
            "layer2.0.downsample.1.running_mean \t torch.Size([256])\n",
            "layer2.0.downsample.1.running_var \t torch.Size([256])\n",
            "layer2.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
            "layer2.1.conv1.0.weight \t torch.Size([256, 256, 3, 3])\n",
            "layer2.1.conv1.0.bias \t torch.Size([256])\n",
            "layer2.1.conv1.1.weight \t torch.Size([256])\n",
            "layer2.1.conv1.1.bias \t torch.Size([256])\n",
            "layer2.1.conv1.1.running_mean \t torch.Size([256])\n",
            "layer2.1.conv1.1.running_var \t torch.Size([256])\n",
            "layer2.1.conv1.1.num_batches_tracked \t torch.Size([])\n",
            "layer2.1.conv2.0.weight \t torch.Size([256, 256, 3, 3])\n",
            "layer2.1.conv2.0.bias \t torch.Size([256])\n",
            "layer2.1.conv2.1.weight \t torch.Size([256])\n",
            "layer2.1.conv2.1.bias \t torch.Size([256])\n",
            "layer2.1.conv2.1.running_mean \t torch.Size([256])\n",
            "layer2.1.conv2.1.running_var \t torch.Size([256])\n",
            "layer2.1.conv2.1.num_batches_tracked \t torch.Size([])\n",
            "layer2.2.conv1.0.weight \t torch.Size([256, 256, 3, 3])\n",
            "layer2.2.conv1.0.bias \t torch.Size([256])\n",
            "layer2.2.conv1.1.weight \t torch.Size([256])\n",
            "layer2.2.conv1.1.bias \t torch.Size([256])\n",
            "layer2.2.conv1.1.running_mean \t torch.Size([256])\n",
            "layer2.2.conv1.1.running_var \t torch.Size([256])\n",
            "layer2.2.conv1.1.num_batches_tracked \t torch.Size([])\n",
            "layer2.2.conv2.0.weight \t torch.Size([256, 256, 3, 3])\n",
            "layer2.2.conv2.0.bias \t torch.Size([256])\n",
            "layer2.2.conv2.1.weight \t torch.Size([256])\n",
            "layer2.2.conv2.1.bias \t torch.Size([256])\n",
            "layer2.2.conv2.1.running_mean \t torch.Size([256])\n",
            "layer2.2.conv2.1.running_var \t torch.Size([256])\n",
            "layer2.2.conv2.1.num_batches_tracked \t torch.Size([])\n",
            "layer2.3.conv1.0.weight \t torch.Size([256, 256, 3, 3])\n",
            "layer2.3.conv1.0.bias \t torch.Size([256])\n",
            "layer2.3.conv1.1.weight \t torch.Size([256])\n",
            "layer2.3.conv1.1.bias \t torch.Size([256])\n",
            "layer2.3.conv1.1.running_mean \t torch.Size([256])\n",
            "layer2.3.conv1.1.running_var \t torch.Size([256])\n",
            "layer2.3.conv1.1.num_batches_tracked \t torch.Size([])\n",
            "layer2.3.conv2.0.weight \t torch.Size([256, 256, 3, 3])\n",
            "layer2.3.conv2.0.bias \t torch.Size([256])\n",
            "layer2.3.conv2.1.weight \t torch.Size([256])\n",
            "layer2.3.conv2.1.bias \t torch.Size([256])\n",
            "layer2.3.conv2.1.running_mean \t torch.Size([256])\n",
            "layer2.3.conv2.1.running_var \t torch.Size([256])\n",
            "layer2.3.conv2.1.num_batches_tracked \t torch.Size([])\n",
            "layer2.4.conv1.0.weight \t torch.Size([256, 256, 3, 3])\n",
            "layer2.4.conv1.0.bias \t torch.Size([256])\n",
            "layer2.4.conv1.1.weight \t torch.Size([256])\n",
            "layer2.4.conv1.1.bias \t torch.Size([256])\n",
            "layer2.4.conv1.1.running_mean \t torch.Size([256])\n",
            "layer2.4.conv1.1.running_var \t torch.Size([256])\n",
            "layer2.4.conv1.1.num_batches_tracked \t torch.Size([])\n",
            "layer2.4.conv2.0.weight \t torch.Size([256, 256, 3, 3])\n",
            "layer2.4.conv2.0.bias \t torch.Size([256])\n",
            "layer2.4.conv2.1.weight \t torch.Size([256])\n",
            "layer2.4.conv2.1.bias \t torch.Size([256])\n",
            "layer2.4.conv2.1.running_mean \t torch.Size([256])\n",
            "layer2.4.conv2.1.running_var \t torch.Size([256])\n",
            "layer2.4.conv2.1.num_batches_tracked \t torch.Size([])\n",
            "layer2.5.conv1.0.weight \t torch.Size([256, 256, 3, 3])\n",
            "layer2.5.conv1.0.bias \t torch.Size([256])\n",
            "layer2.5.conv1.1.weight \t torch.Size([256])\n",
            "layer2.5.conv1.1.bias \t torch.Size([256])\n",
            "layer2.5.conv1.1.running_mean \t torch.Size([256])\n",
            "layer2.5.conv1.1.running_var \t torch.Size([256])\n",
            "layer2.5.conv1.1.num_batches_tracked \t torch.Size([])\n",
            "layer2.5.conv2.0.weight \t torch.Size([256, 256, 3, 3])\n",
            "layer2.5.conv2.0.bias \t torch.Size([256])\n",
            "layer2.5.conv2.1.weight \t torch.Size([256])\n",
            "layer2.5.conv2.1.bias \t torch.Size([256])\n",
            "layer2.5.conv2.1.running_mean \t torch.Size([256])\n",
            "layer2.5.conv2.1.running_var \t torch.Size([256])\n",
            "layer2.5.conv2.1.num_batches_tracked \t torch.Size([])\n",
            "layer3.0.conv1.0.weight \t torch.Size([512, 256, 3, 3])\n",
            "layer3.0.conv1.0.bias \t torch.Size([512])\n",
            "layer3.0.conv1.1.weight \t torch.Size([512])\n",
            "layer3.0.conv1.1.bias \t torch.Size([512])\n",
            "layer3.0.conv1.1.running_mean \t torch.Size([512])\n",
            "layer3.0.conv1.1.running_var \t torch.Size([512])\n",
            "layer3.0.conv1.1.num_batches_tracked \t torch.Size([])\n",
            "layer3.0.conv2.0.weight \t torch.Size([512, 512, 3, 3])\n",
            "layer3.0.conv2.0.bias \t torch.Size([512])\n",
            "layer3.0.conv2.1.weight \t torch.Size([512])\n",
            "layer3.0.conv2.1.bias \t torch.Size([512])\n",
            "layer3.0.conv2.1.running_mean \t torch.Size([512])\n",
            "layer3.0.conv2.1.running_var \t torch.Size([512])\n",
            "layer3.0.conv2.1.num_batches_tracked \t torch.Size([])\n",
            "layer3.0.downsample.0.weight \t torch.Size([512, 256, 1, 1])\n",
            "layer3.0.downsample.0.bias \t torch.Size([512])\n",
            "layer3.0.downsample.1.weight \t torch.Size([512])\n",
            "layer3.0.downsample.1.bias \t torch.Size([512])\n",
            "layer3.0.downsample.1.running_mean \t torch.Size([512])\n",
            "layer3.0.downsample.1.running_var \t torch.Size([512])\n",
            "layer3.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
            "layer3.1.conv1.0.weight \t torch.Size([512, 512, 3, 3])\n",
            "layer3.1.conv1.0.bias \t torch.Size([512])\n",
            "layer3.1.conv1.1.weight \t torch.Size([512])\n",
            "layer3.1.conv1.1.bias \t torch.Size([512])\n",
            "layer3.1.conv1.1.running_mean \t torch.Size([512])\n",
            "layer3.1.conv1.1.running_var \t torch.Size([512])\n",
            "layer3.1.conv1.1.num_batches_tracked \t torch.Size([])\n",
            "layer3.1.conv2.0.weight \t torch.Size([512, 512, 3, 3])\n",
            "layer3.1.conv2.0.bias \t torch.Size([512])\n",
            "layer3.1.conv2.1.weight \t torch.Size([512])\n",
            "layer3.1.conv2.1.bias \t torch.Size([512])\n",
            "layer3.1.conv2.1.running_mean \t torch.Size([512])\n",
            "layer3.1.conv2.1.running_var \t torch.Size([512])\n",
            "layer3.1.conv2.1.num_batches_tracked \t torch.Size([])\n",
            "layer3.2.conv1.0.weight \t torch.Size([512, 512, 3, 3])\n",
            "layer3.2.conv1.0.bias \t torch.Size([512])\n",
            "layer3.2.conv1.1.weight \t torch.Size([512])\n",
            "layer3.2.conv1.1.bias \t torch.Size([512])\n",
            "layer3.2.conv1.1.running_mean \t torch.Size([512])\n",
            "layer3.2.conv1.1.running_var \t torch.Size([512])\n",
            "layer3.2.conv1.1.num_batches_tracked \t torch.Size([])\n",
            "layer3.2.conv2.0.weight \t torch.Size([512, 512, 3, 3])\n",
            "layer3.2.conv2.0.bias \t torch.Size([512])\n",
            "layer3.2.conv2.1.weight \t torch.Size([512])\n",
            "layer3.2.conv2.1.bias \t torch.Size([512])\n",
            "layer3.2.conv2.1.running_mean \t torch.Size([512])\n",
            "layer3.2.conv2.1.running_var \t torch.Size([512])\n",
            "layer3.2.conv2.1.num_batches_tracked \t torch.Size([])\n",
            "fc.weight \t torch.Size([10, 512])\n",
            "fc.bias \t torch.Size([10])\n",
            "Optimizer's state_dict:\n",
            "state \t {}\n",
            "param_groups \t [{'lr': 0.01, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0.001, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]}]\n"
          ]
        }
      ],
      "source": [
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "# Print optimizer's state_dict\n",
        "print(\"Optimizer's state_dict:\")\n",
        "for var_name in optimizer.state_dict():\n",
        "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZAW_ob6r8BD"
      },
      "source": [
        "# Saving For Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "z9OgkYGDr_Td"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/content/models/model_state.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRB11x-xHEF5"
      },
      "source": [
        "# Training\n",
        "\n",
        "To know how model training works in PyTorch:\n",
        "\n",
        "1. We start by loading the images in batches using our train_loader for every epoch, and also move the data to the GPU using the device variable we defined earlier\n",
        "2. The model is then used to predict on the labels, model(images), and then we calculate the loss between the predictions and the ground truth using the loss function defined above, criterion(outputs, labels)\n",
        "3. Now the learning part comes, we use the loss to backpropagate method, loss.backward(), and update the weights, optimizer.step(). One important thing that is required before every update is to set the gradients to zero using optimizer.zero_grad() because otherwise the gradients are accumulated (default behaviour in PyTorch)\n",
        "4. Lastly, after every epoch, we test our model on the validation set, but, as we don't need gradients when evaluating, we can turn it off using with torch.no_grad() to make the evaluation much faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eKt2SqLxHkr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6e68fe1-ec89-40ab-d620-6bf407086c58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 0.7372\n",
            "Accuracy of the network on the 5000 validation images: 60.78 %\n",
            "Epoch [2/20], Loss: 0.2902\n",
            "Accuracy of the network on the 5000 validation images: 70.02 %\n",
            "Epoch [3/20], Loss: 0.4519\n",
            "Accuracy of the network on the 5000 validation images: 78.82 %\n",
            "Epoch [4/20], Loss: 1.4316\n",
            "Accuracy of the network on the 5000 validation images: 78.6 %\n",
            "Epoch [5/20], Loss: 1.3437\n",
            "Accuracy of the network on the 5000 validation images: 81.2 %\n",
            "Epoch [6/20], Loss: 0.3796\n",
            "Accuracy of the network on the 5000 validation images: 82.3 %\n",
            "Epoch [7/20], Loss: 0.1566\n",
            "Accuracy of the network on the 5000 validation images: 82.44 %\n",
            "Epoch [8/20], Loss: 0.1783\n",
            "Accuracy of the network on the 5000 validation images: 82.42 %\n",
            "Epoch [9/20], Loss: 0.1512\n",
            "Accuracy of the network on the 5000 validation images: 83.0 %\n",
            "Epoch [10/20], Loss: 0.2589\n",
            "Accuracy of the network on the 5000 validation images: 83.62 %\n",
            "Epoch [11/20], Loss: 0.2438\n",
            "Accuracy of the network on the 5000 validation images: 83.8 %\n",
            "Epoch [12/20], Loss: 0.2451\n",
            "Accuracy of the network on the 5000 validation images: 84.34 %\n",
            "Epoch [13/20], Loss: 0.6535\n",
            "Accuracy of the network on the 5000 validation images: 82.92 %\n",
            "Epoch [14/20], Loss: 1.7722\n",
            "Accuracy of the network on the 5000 validation images: 83.94 %\n",
            "Epoch [15/20], Loss: 0.0842\n",
            "Accuracy of the network on the 5000 validation images: 82.56 %\n",
            "Epoch [16/20], Loss: 0.0203\n",
            "Accuracy of the network on the 5000 validation images: 84.22 %\n",
            "Epoch [17/20], Loss: 0.2710\n",
            "Accuracy of the network on the 5000 validation images: 84.06 %\n",
            "Epoch [18/20], Loss: 0.1214\n",
            "Accuracy of the network on the 5000 validation images: 84.4 %\n",
            "Epoch [19/20], Loss: 0.1518\n",
            "Accuracy of the network on the 5000 validation images: 82.58 %\n",
            "Epoch [20/20], Loss: 0.0763\n",
            "Accuracy of the network on the 5000 validation images: 83.64 %\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        del images, labels, outputs\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    print ('Epoch [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, loss.item()))\n",
        "            \n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images, labels, outputs\n",
        "    \n",
        "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUDUdq3FHtV4"
      },
      "source": [
        "## We can see that the model is learning as the loss is decreasing while the accuracy on the validation set is increasing with every epoch. But we may notice that it is fluctuating at the end, which could mean the model is overfitting or that the batch_size is small."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exrDgPfeH04Y"
      },
      "source": [
        "# Testing\n",
        "\n",
        "For testing, we use exactly the same code as validation but with the test_loader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RY7EIoeGHyo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "308b7b63-6467-4b27-927e-e37ae25dce51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 83.12 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4zx_hiTtj7U"
      },
      "source": [
        "# Saving The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3D7Uoz-Xtmsa"
      },
      "outputs": [],
      "source": [
        "torch.save(model, '/content/models/model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMmS67BwuF3z"
      },
      "source": [
        "# Loading The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GDcpztnquNhZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dea35d2-d766-4fe8-d8fe-cf29659562b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer0): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (layer1): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (5): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): ResidualBlock(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model = torch.load('/content/models/model.pth')\n",
        "model.eval()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}