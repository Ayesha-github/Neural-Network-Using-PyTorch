{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPb4qF7g0vHFJem+vuV1uvr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Engineer-Ayesha-Shafique/Neural-Network-Using-PyTorch/blob/main/GoogleNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#An implementation of GoogLeNet / InceptionNet from scratch.\n",
        "\n",
        "This notebook contains an implementation of GoogleNet, also known as Inception v1, using PyTorch. GoogleNet is a deep convolutional neural network architecture that was developed by Google for image classification tasks. It was the winner of the 2014 ImageNet Large Scale Visual Recognition Challenge.\n",
        "\n",
        "The code in this repository is designed to be easy to understand and modify, while still providing a high-performance implementation of the GoogleNet architecture. The implementation includes all of the key components of the original GoogleNet architecture, including the use of inception modules, which allow the network to learn both local and global features."
      ],
      "metadata": {
        "id": "0YfO8EcJsYIO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5dsSjDnsQ4M"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogLeNet(nn.Module):\n",
        "    def __init__(self, aux_logits=True, num_classes=1000):\n",
        "        super(GoogLeNet, self).__init__()\n",
        "        assert aux_logits == True or aux_logits == False\n",
        "        self.aux_logits = aux_logits\n",
        "\n",
        "        # Write in_channels, etc, all explicit in self.conv1, rest will write to\n",
        "        # make everything as compact as possible, kernel_size=3 instead of (3,3)\n",
        "        self.conv1 = conv_block(\n",
        "            in_channels=3,\n",
        "            out_channels=64,\n",
        "            kernel_size=7,\n",
        "            stride=2,\n",
        "            padding=3,\n",
        "        )\n",
        "\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.conv2 = conv_block(64, 192, kernel_size=3, stride=1, padding=1)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # In this order: in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool\n",
        "        self.inception3a = Inception_block(192, 64, 96, 128, 16, 32, 32)\n",
        "        self.inception3b = Inception_block(256, 128, 128, 192, 32, 96, 64)\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.inception4a = Inception_block(480, 192, 96, 208, 16, 48, 64)\n",
        "        self.inception4b = Inception_block(512, 160, 112, 224, 24, 64, 64)\n",
        "        self.inception4c = Inception_block(512, 128, 128, 256, 24, 64, 64)\n",
        "        self.inception4d = Inception_block(512, 112, 144, 288, 32, 64, 64)\n",
        "        self.inception4e = Inception_block(528, 256, 160, 320, 32, 128, 128)\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.inception5a = Inception_block(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5b = Inception_block(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
        "        self.dropout = nn.Dropout(p=0.4)\n",
        "        self.fc1 = nn.Linear(1024, num_classes)\n",
        "\n",
        "        if self.aux_logits:\n",
        "            self.aux1 = InceptionAux(512, num_classes)\n",
        "            self.aux2 = InceptionAux(528, num_classes)\n",
        "        else:\n",
        "            self.aux1 = self.aux2 = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        x = self.inception3a(x)\n",
        "        x = self.inception3b(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        x = self.inception4a(x)\n",
        "\n",
        "        # Auxiliary Softmax classifier 1\n",
        "        if self.aux_logits and self.training:\n",
        "            aux1 = self.aux1(x)\n",
        "\n",
        "        x = self.inception4b(x)\n",
        "        x = self.inception4c(x)\n",
        "        x = self.inception4d(x)\n",
        "\n",
        "        # Auxiliary Softmax classifier 2\n",
        "        if self.aux_logits and self.training:\n",
        "            aux2 = self.aux2(x)\n",
        "\n",
        "        x = self.inception4e(x)\n",
        "        x = self.maxpool4(x)\n",
        "        x = self.inception5a(x)\n",
        "        x = self.inception5b(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        if self.aux_logits and self.training:\n",
        "            return aux1, aux2, x\n",
        "        else:\n",
        "            return x"
      ],
      "metadata": {
        "id": "yYkmrjO9se5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Inception_block(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool\n",
        "    ):\n",
        "        super(Inception_block, self).__init__()\n",
        "        self.branch1 = conv_block(in_channels, out_1x1, kernel_size=1)\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            conv_block(in_channels, red_3x3, kernel_size=1),\n",
        "            conv_block(red_3x3, out_3x3, kernel_size=(3, 3), padding=1),\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.Sequential(\n",
        "            conv_block(in_channels, red_5x5, kernel_size=1),\n",
        "            conv_block(red_5x5, out_5x5, kernel_size=5, padding=2),\n",
        "        )\n",
        "\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            conv_block(in_channels, out_1x1pool, kernel_size=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat(\n",
        "            [self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], 1\n",
        "        )"
      ],
      "metadata": {
        "id": "s4qi2Kr-sicb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionAux(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(InceptionAux, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.7)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=5, stride=3)\n",
        "        self.conv = conv_block(in_channels, 128, kernel_size=1)\n",
        "        self.fc1 = nn.Linear(2048, 1024)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(x)\n",
        "        x = self.conv(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "59yRsHJXsjCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class conv_block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, **kwargs):\n",
        "        super(conv_block, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(self.batchnorm(self.conv(x)))"
      ],
      "metadata": {
        "id": "1_G5JI9nslpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    BATCH_SIZE = 5 \n",
        "    x = torch.randn(BATCH_SIZE, 3, 224, 224)\n",
        "    model = GoogLeNet(aux_logits=True, num_classes=1000)\n",
        "    summary(model, (3, 224, 224))\n",
        "    print(model(x)[2].shape)\n",
        "    assert model(x)[2].shape == torch.Size([BATCH_SIZE, 1000])"
      ],
      "metadata": {
        "id": "HoVM2xUJsoIZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}